{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f07e54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data analysis and visualization\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# Preprocessing and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "469e18e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train , y_train), (X_test , y_test) = tf.keras.datasets.boston_housing.load_data(\n",
    "                                            path = 'boston_housing_npz',\n",
    "                                            test_split = 0.2,\n",
    "                                            seed = 42\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27927e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(((404, 13), numpy.ndarray),\n",
       " ((102, 13), numpy.ndarray),\n",
       " ((404,), numpy.ndarray),\n",
       " ((102,), numpy.ndarray))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the data shape and type\n",
    "(X_train.shape, type(X_train)), (X_test.shape, type(X_test)), (y_train.shape, type(y_train)), (y_test.shape, type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61a41376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.09178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.510</td>\n",
       "      <td>6.416</td>\n",
       "      <td>84.1</td>\n",
       "      <td>2.6463</td>\n",
       "      <td>5.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>395.50</td>\n",
       "      <td>9.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.05644</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.447</td>\n",
       "      <td>6.758</td>\n",
       "      <td>32.9</td>\n",
       "      <td>4.0776</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>396.90</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.983</td>\n",
       "      <td>98.8</td>\n",
       "      <td>1.8681</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>390.11</td>\n",
       "      <td>18.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.09164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.413</td>\n",
       "      <td>6.065</td>\n",
       "      <td>7.8</td>\n",
       "      <td>5.2873</td>\n",
       "      <td>4.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>390.91</td>\n",
       "      <td>5.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.09017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713</td>\n",
       "      <td>6.297</td>\n",
       "      <td>91.8</td>\n",
       "      <td>2.3682</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>385.09</td>\n",
       "      <td>17.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.10153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437</td>\n",
       "      <td>6.279</td>\n",
       "      <td>74.5</td>\n",
       "      <td>4.0522</td>\n",
       "      <td>5.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>373.66</td>\n",
       "      <td>11.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.31827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.544</td>\n",
       "      <td>5.914</td>\n",
       "      <td>83.2</td>\n",
       "      <td>3.9986</td>\n",
       "      <td>4.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>390.70</td>\n",
       "      <td>18.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.29090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.624</td>\n",
       "      <td>6.174</td>\n",
       "      <td>93.6</td>\n",
       "      <td>1.6119</td>\n",
       "      <td>4.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>388.08</td>\n",
       "      <td>24.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.03841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532</td>\n",
       "      <td>6.229</td>\n",
       "      <td>90.7</td>\n",
       "      <td>3.0993</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>395.33</td>\n",
       "      <td>12.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.22438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>6.027</td>\n",
       "      <td>79.7</td>\n",
       "      <td>2.4982</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>14.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1      2    3      4      5     6       7     8      9     10  \\\n",
       "0  0.09178   0.0   4.05  0.0  0.510  6.416  84.1  2.6463   5.0  296.0  16.6   \n",
       "1  0.05644  40.0   6.41  1.0  0.447  6.758  32.9  4.0776   4.0  254.0  17.6   \n",
       "2  0.10574   0.0  27.74  0.0  0.609  5.983  98.8  1.8681   4.0  711.0  20.1   \n",
       "3  0.09164   0.0  10.81  0.0  0.413  6.065   7.8  5.2873   4.0  305.0  19.2   \n",
       "4  5.09017   0.0  18.10  0.0  0.713  6.297  91.8  2.3682  24.0  666.0  20.2   \n",
       "5  0.10153   0.0  12.83  0.0  0.437  6.279  74.5  4.0522   5.0  398.0  18.7   \n",
       "6  0.31827   0.0   9.90  0.0  0.544  5.914  83.2  3.9986   4.0  304.0  18.4   \n",
       "7  0.29090   0.0  21.89  0.0  0.624  6.174  93.6  1.6119   4.0  437.0  21.2   \n",
       "8  4.03841   0.0  18.10  0.0  0.532  6.229  90.7  3.0993  24.0  666.0  20.2   \n",
       "9  0.22438   0.0   9.69  0.0  0.585  6.027  79.7  2.4982   6.0  391.0  19.2   \n",
       "\n",
       "       11     12  \n",
       "0  395.50   9.04  \n",
       "1  396.90   3.53  \n",
       "2  390.11  18.07  \n",
       "3  390.91   5.52  \n",
       "4  385.09  17.27  \n",
       "5  373.66  11.97  \n",
       "6  390.70  18.33  \n",
       "7  388.08  24.16  \n",
       "8  395.33  12.87  \n",
       "9  396.90  14.33  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converting Data to DataFrame \n",
    "X_train_df = pd.DataFrame(X_train)\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "\n",
    "# Preview the training data\n",
    "X_train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00edc57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 404 entries, 0 to 403\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       404 non-null    float64\n",
      " 1   1       404 non-null    float64\n",
      " 2   2       404 non-null    float64\n",
      " 3   3       404 non-null    float64\n",
      " 4   4       404 non-null    float64\n",
      " 5   5       404 non-null    float64\n",
      " 6   6       404 non-null    float64\n",
      " 7   7       404 non-null    float64\n",
      " 8   8       404 non-null    float64\n",
      " 9   9       404 non-null    float64\n",
      " 10  10      404 non-null    float64\n",
      " 11  11      404 non-null    float64\n",
      " 12  12      404 non-null    float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 41.2 KB\n",
      "________________________________________\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 404 entries, 0 to 403\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       404 non-null    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 3.3 KB\n"
     ]
    }
   ],
   "source": [
    "# View summary of datasets\n",
    "X_train_df.info()\n",
    "print('_'*40)\n",
    "y_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e077ec62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.789989</td>\n",
       "      <td>11.568069</td>\n",
       "      <td>11.214059</td>\n",
       "      <td>0.069307</td>\n",
       "      <td>0.554524</td>\n",
       "      <td>6.284824</td>\n",
       "      <td>69.119307</td>\n",
       "      <td>3.792258</td>\n",
       "      <td>9.660891</td>\n",
       "      <td>408.960396</td>\n",
       "      <td>18.481931</td>\n",
       "      <td>356.293020</td>\n",
       "      <td>12.825520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.132761</td>\n",
       "      <td>24.269648</td>\n",
       "      <td>6.925462</td>\n",
       "      <td>0.254290</td>\n",
       "      <td>0.116408</td>\n",
       "      <td>0.723759</td>\n",
       "      <td>28.034606</td>\n",
       "      <td>2.142651</td>\n",
       "      <td>8.736073</td>\n",
       "      <td>169.685166</td>\n",
       "      <td>2.157322</td>\n",
       "      <td>92.058615</td>\n",
       "      <td>7.308772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.137000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.081960</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.452000</td>\n",
       "      <td>5.878750</td>\n",
       "      <td>45.475000</td>\n",
       "      <td>2.097050</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.085000</td>\n",
       "      <td>7.092500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.262660</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.210000</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.167500</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>391.305000</td>\n",
       "      <td>11.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.717875</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.620500</td>\n",
       "      <td>94.425000</td>\n",
       "      <td>5.118000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>395.810000</td>\n",
       "      <td>17.167500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.000000   \n",
       "mean     3.789989   11.568069   11.214059    0.069307    0.554524    6.284824   \n",
       "std      9.132761   24.269648    6.925462    0.254290    0.116408    0.723759   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.081960    0.000000    5.190000    0.000000    0.452000    5.878750   \n",
       "50%      0.262660    0.000000    9.690000    0.000000    0.538000    6.210000   \n",
       "75%      3.717875   12.500000   18.100000    0.000000    0.624000    6.620500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.000000   \n",
       "mean    69.119307    3.792258    9.660891  408.960396   18.481931  356.293020   \n",
       "std     28.034606    2.142651    8.736073  169.685166    2.157322   92.058615   \n",
       "min      2.900000    1.137000    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.475000    2.097050    4.000000  281.000000   17.400000  375.085000   \n",
       "50%     77.500000    3.167500    5.000000  330.000000   19.100000  391.305000   \n",
       "75%     94.425000    5.118000   24.000000  666.000000   20.200000  395.810000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "               12  \n",
       "count  404.000000  \n",
       "mean    12.825520  \n",
       "std      7.308772  \n",
       "min      1.920000  \n",
       "25%      7.092500  \n",
       "50%     11.560000  \n",
       "75%     17.167500  \n",
       "max     37.970000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distribution of numerical feature values across the samples\n",
    "X_train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42bb5279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>404.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.042528</td>\n",
       "      <td>0.115681</td>\n",
       "      <td>0.394210</td>\n",
       "      <td>0.348815</td>\n",
       "      <td>0.521906</td>\n",
       "      <td>0.681970</td>\n",
       "      <td>0.241618</td>\n",
       "      <td>0.376561</td>\n",
       "      <td>0.423589</td>\n",
       "      <td>0.625738</td>\n",
       "      <td>0.897607</td>\n",
       "      <td>0.302511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.102650</td>\n",
       "      <td>0.242696</td>\n",
       "      <td>0.253866</td>\n",
       "      <td>0.239522</td>\n",
       "      <td>0.138678</td>\n",
       "      <td>0.288719</td>\n",
       "      <td>0.194973</td>\n",
       "      <td>0.379829</td>\n",
       "      <td>0.323827</td>\n",
       "      <td>0.229502</td>\n",
       "      <td>0.232131</td>\n",
       "      <td>0.202740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173387</td>\n",
       "      <td>0.137860</td>\n",
       "      <td>0.444098</td>\n",
       "      <td>0.438466</td>\n",
       "      <td>0.087361</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.179389</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.944992</td>\n",
       "      <td>0.143481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.002881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338343</td>\n",
       "      <td>0.314815</td>\n",
       "      <td>0.507569</td>\n",
       "      <td>0.768280</td>\n",
       "      <td>0.184767</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.272901</td>\n",
       "      <td>0.691489</td>\n",
       "      <td>0.985892</td>\n",
       "      <td>0.267406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.041717</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.646628</td>\n",
       "      <td>0.491770</td>\n",
       "      <td>0.586223</td>\n",
       "      <td>0.942585</td>\n",
       "      <td>0.362255</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914122</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.997252</td>\n",
       "      <td>0.422954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.000000   \n",
       "mean     0.042528    0.115681    0.394210    0.348815    0.521906    0.681970   \n",
       "std      0.102650    0.242696    0.253866    0.239522    0.138678    0.288719   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000850    0.000000    0.173387    0.137860    0.444098    0.438466   \n",
       "50%      0.002881    0.000000    0.338343    0.314815    0.507569    0.768280   \n",
       "75%      0.041717    0.125000    0.646628    0.491770    0.586223    0.942585   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "               6           7           8           9           10          11  \n",
       "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.000000  \n",
       "mean     0.241618    0.376561    0.423589    0.625738    0.897607    0.302511  \n",
       "std      0.194973    0.379829    0.323827    0.229502    0.232131    0.202740  \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.087361    0.130435    0.179389    0.510638    0.944992    0.143481  \n",
       "50%      0.184767    0.173913    0.272901    0.691489    0.985892    0.267406  \n",
       "75%      0.362255    1.000000    0.914122    0.808511    0.997252    0.422954  \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create column transformer\n",
    "ct = make_column_transformer(\n",
    "    (MinMaxScaler(), [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12])\n",
    ")\n",
    "\n",
    "# Normalization and data type change\n",
    "X_train = ct.fit_transform(X_train).astype('float32')\n",
    "X_test = ct.transform(X_test).astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "\n",
    "# Distribution of X_train feature values after normalization\n",
    "pd.DataFrame(X_train).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c5d5c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((363, 12), (41, 12), (363,), (41,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reserve data for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0000a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 2s 47ms/step - loss: 251.7491 - mse: 251.7491 - val_loss: 108.0996 - val_mse: 108.0996\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 75.8593 - mse: 75.8593 - val_loss: 82.4522 - val_mse: 82.4522\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 57.7669 - mse: 57.7669 - val_loss: 64.1342 - val_mse: 64.1342\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 47.8395 - mse: 47.8395 - val_loss: 54.4725 - val_mse: 54.4725\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 45.1098 - mse: 45.1098 - val_loss: 72.1685 - val_mse: 72.1685\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 38.3140 - mse: 38.3140 - val_loss: 61.4606 - val_mse: 61.4606\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 33.2184 - mse: 33.2184 - val_loss: 36.1710 - val_mse: 36.1710\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 30.3241 - mse: 30.3241 - val_loss: 41.3227 - val_mse: 41.3227\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 29.9364 - mse: 29.9364 - val_loss: 32.9640 - val_mse: 32.9640\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 30.2946 - mse: 30.2946 - val_loss: 42.2841 - val_mse: 42.2841\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 24.7659 - mse: 24.7659 - val_loss: 47.1784 - val_mse: 47.1784\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 28.4647 - mse: 28.4647 - val_loss: 30.9841 - val_mse: 30.9841\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 23.5413 - mse: 23.5413 - val_loss: 54.6545 - val_mse: 54.6545\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 25.3602 - mse: 25.3602 - val_loss: 21.4459 - val_mse: 21.4459\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 24.4690 - mse: 24.4690 - val_loss: 21.4464 - val_mse: 21.4464\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 23.1218 - mse: 23.1218 - val_loss: 25.4713 - val_mse: 25.4713\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 23.4312 - mse: 23.4312 - val_loss: 41.9818 - val_mse: 41.9818\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 24.1627 - mse: 24.1627 - val_loss: 20.9780 - val_mse: 20.9780\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 20.5979 - mse: 20.5979 - val_loss: 19.6290 - val_mse: 19.6290\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 24.2246 - mse: 24.2246 - val_loss: 23.9481 - val_mse: 23.9481\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 23.4324 - mse: 23.4324 - val_loss: 20.0910 - val_mse: 20.0910\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 18.7056 - mse: 18.7056 - val_loss: 67.9344 - val_mse: 67.9344\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 22.7477 - mse: 22.7477 - val_loss: 18.0766 - val_mse: 18.0766\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 22.1919 - mse: 22.1919 - val_loss: 19.4536 - val_mse: 19.4536\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 19.4806 - mse: 19.4806 - val_loss: 35.8169 - val_mse: 35.8169\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 20.5005 - mse: 20.5005 - val_loss: 44.0043 - val_mse: 44.0043\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 19.2276 - mse: 19.2276 - val_loss: 23.4341 - val_mse: 23.4341\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 18.6589 - mse: 18.6589 - val_loss: 16.4197 - val_mse: 16.4197\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 21.0778 - mse: 21.0778 - val_loss: 33.7285 - val_mse: 33.7285\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 21.3424 - mse: 21.3424 - val_loss: 44.0118 - val_mse: 44.0118\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 21.3959 - mse: 21.3959 - val_loss: 26.3787 - val_mse: 26.3787\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 17.4104 - mse: 17.4104 - val_loss: 22.7284 - val_mse: 22.7284\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 17.9472 - mse: 17.9472 - val_loss: 19.0800 - val_mse: 19.0800\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 18.2776 - mse: 18.2776 - val_loss: 15.0666 - val_mse: 15.0666\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 18.7611 - mse: 18.7611 - val_loss: 13.4422 - val_mse: 13.4422\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 18.3765 - mse: 18.3765 - val_loss: 21.4277 - val_mse: 21.4277\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 19.7825 - mse: 19.7825 - val_loss: 33.9145 - val_mse: 33.9145\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 17.0963 - mse: 17.0963 - val_loss: 19.5967 - val_mse: 19.5967\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 17.2470 - mse: 17.2470 - val_loss: 13.0157 - val_mse: 13.0157\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 16.8442 - mse: 16.8442 - val_loss: 13.8760 - val_mse: 13.8760\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 18.1785 - mse: 18.1785 - val_loss: 15.3982 - val_mse: 15.3982\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 16.1199 - mse: 16.1199 - val_loss: 22.7427 - val_mse: 22.7427\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 20.0635 - mse: 20.0635 - val_loss: 19.0613 - val_mse: 19.0613\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 14.8684 - mse: 14.8684 - val_loss: 11.6322 - val_mse: 11.6322\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 18.5755 - mse: 18.5755 - val_loss: 26.5506 - val_mse: 26.5506\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 17.3508 - mse: 17.3508 - val_loss: 13.4359 - val_mse: 13.4359\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 17.4421 - mse: 17.4421 - val_loss: 21.9458 - val_mse: 21.9458\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 16.1806 - mse: 16.1806 - val_loss: 22.7394 - val_mse: 22.7394\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 15.8323 - mse: 15.8323 - val_loss: 12.0656 - val_mse: 12.0656\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 17.1271 - mse: 17.1271 - val_loss: 11.3767 - val_mse: 11.3767\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Building the model\n",
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(units=10, activation='relu', input_shape=(X_train.shape[1],), name='Dense_1'),\n",
    "  tf.keras.layers.Dense(units=100, activation='relu', name='Dense_2'),\n",
    "  tf.keras.layers.Dense(units=1, name='Prediction')\n",
    "])\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(\n",
    "    loss = tf.keras.losses.mean_squared_error,\n",
    "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.01),\n",
    "    metrics = ['mse']\n",
    ")\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=50,\n",
    "    validation_data=(X_val, y_val)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76b2e66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22.235537, 24.89756)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the mean value of training and validation data\n",
    "y_train.mean(), y_val.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa827b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on Test data \n",
      "\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 16.4087 - mse: 16.4087\n",
      "\n",
      "Model loss on test set: 16.40869903564453\n",
      "Model mean squared error on test set: 16.41\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "print(\"Evaluation on Test data \\n\")\n",
    "loss, mse = model.evaluate(X_test, y_test, batch_size=32)\n",
    "print(f\"\\nModel loss on test set: {loss}\")\n",
    "print(f\"Model mean squared error on test set: {(mse):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83208ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABHkElEQVR4nO3dd3xUVfrH8c8zk0kmHQIpECCh10DQgAoKKCoq2F0XK7r2iq7Lqru/ta3u2ta69rWuomJbEVApgogiPfRe0nsgPZlk5vz+mCEGSCBAJhOY5/165ZWZM/feeW7E+c655RwxxqCUUkoBWHxdgFJKqbZDQ0EppVQ9DQWllFL1NBSUUkrV01BQSilVT0NBKaVUPQ0FpZRS9TQU1HFFRHaJyJk+eu/hIjJLRPaISLGILBWR631Ri1JHSkNBqRYgIqcAPwA/Ar2ADsBtwLlHuD1ry1WnVPNpKCi/ICJBIvKCiGR7fl4QkSDPax1FZEaDb/g/iYjF89r9IpIlImUisllExjbxFs8A7xtjnjLGFBq3FcaYyz3buU5EFu1XkxGRXp7H74nIa56eRgXwoIjkNgwHEblYRNZ4HltE5AER2S4iRSIyTUSiPK/ZReRDT/seEVkmIrEt/CdVxykNBeUv/gqcDCQDQ4DhwP95XrsPyASigVjgL4ARkb7AncAwY0w4MA7Ytf+GRSQEOAX4/ChrvBJ4AggHngUqgDP2e32q5/HdwEXAaKAzsBt4xfPaJCAS6Iq7x3IrUHWUtSk/oaGg/MVVwGPGmHxjTAHwKHCN57VaoBOQYIypNcb8ZNyDgjmBIGCAiNiMMbuMMdsb2XZ73P8v5RxljV8bY342xriMMdXAx8AVACISDpznaQO4BfirMSbTGFMDPAJcJiIBnv3pAPQyxjg9PZbSo6xN+QkNBeUvOgNpDZ6nedrAfehnGzBbRHaIyAMAxphtwD24P3DzReQTEenMgXYDLtzBcjQy9ns+FbjEc5jrEmClMWbvPiQAX3kOD+0BNuIOsVjgv8D3wCeeQ2VPi4jtKGtTfkJDQfmLbNwfpHt187RhjCkzxtxnjOkBnA/8ce+5A2PMVGPMqZ51DfDU/hs2xlQCi4FLD/L+FUDI3iciEtfIMvsMWWyM2YA7vM5l30NH4A6Qc40x7Rr82I0xWZ7ezqPGmAHACGACcO1BalOqnoaCOh7ZPCdb9/4E4D7s8n8iEi0iHYGHgA8BRGSCiPQSEQFKcX/jdopIXxE5w/NNvRr3cXlnE+/5Z+A6EZkiIh082x0iIp94Xl8NDBSRZBGx4+59NMdU3OcPRgGfNWh/HXhCRBI87xUtIhd6Hp8uIkmek9SluA8nNVW3UvvQUFDHo1m4P8D3/jwCPA4sB9YAa4GVnjaA3sBcoBz3N/5XjTELcJ9PeBIoBHKBGNwnoQ9gjPkF90nhM4AdIlIMvOmpBWPMFuAxz/tsBRY1tp1GfAyMAX4wxhQ2aH8RmI77kFcZ8Ctwkue1ONwnvUtxH1b6EU8AKnUoopPsKKWU2kt7CkoppeppKCillKqnoaCUUqqehoJSSql6Ab4u4Gh07NjRJCYm+roMpZQ6pqxYsaLQGBPd2GvHdCgkJiayfPlyX5ehlFLHFBFJa+o1PXyklFKqnoaCUkqpehoKSiml6h3T5xSUUv6ltraWzMxMqqurfV3KMcFut9OlSxdstuYPkquhoJQ6ZmRmZhIeHk5iYiLu8QtVU4wxFBUVkZmZSffu3Zu9nh4+UkodM6qrq+nQoYMGQjOICB06dDjsXpWGglLqmKKB0HxH8rfyWiiISFcRmS8iG0VkvYhM9rQ/4pkIPdXzc16DdR4UkW2eCdLHeau23Ixt/PqfP5KxdbW33kIppY5J3uwp1AH3GWP6454w/Q4RGeB57XljTLLnZxaA57WJwEDgHOBVzyQhLa6sKIeTM9+maNd6b2xeKXUcCwsL83UJXuW1UDDG5BhjVnoel+Ge7CP+IKtcCHxijKkxxuzEPWfucG/UFhgcDkBdTbk3Nq+UUsesVjmnICKJwFBgiafpThFZIyLviEh7T1s8+05cnkkjISIiN4vIchFZXlBQcET1BIW4k95VU3FE6yullDGGKVOmMGjQIJKSkvj0008ByMnJYdSoUSQnJzNo0CB++uknnE4n1113Xf2yzz//vI+rb5rXL0kVkTDgC+AeY0ypiLwG/B33JOV/B/4F/AFo7IzIAdPCGWPexD3NISkpKUc0bVxwiLunoKGg1LHr0W/WsyG7tEW3OaBzBA+fP7BZy3755ZekpqayevVqCgsLGTZsGKNGjWLq1KmMGzeOv/71rzidTiorK0lNTSUrK4t169YBsGfPnhatuyV5tacgIjbcgfCRMeZLAGNMnjHGaYxxAW/x2yGiTKBrg9W7ANneqMse6g4FHJXe2LxSyg8sWrSIK664AqvVSmxsLKNHj2bZsmUMGzaMd999l0ceeYS1a9cSHh5Ojx492LFjB3fddRffffcdERERvi6/SV7rKYj7Wqi3gY3GmOcatHcyxuR4nl4MrPM8ng5MFZHngM64J1Nf6o3aAgPt1BkLplZ7Ckodq5r7jd5bmprfftSoUSxcuJCZM2dyzTXXMGXKFK699lpWr17N999/zyuvvMK0adN45513Wrni5vFmT2EkcA1wxn6Xnz4tImtFZA1wOnAvgDFmPTAN2AB8B9xhjHF6ozCxWKgiCKnVnoJS6siMGjWKTz/9FKfTSUFBAQsXLmT48OGkpaURExPDTTfdxA033MDKlSspLCzE5XJx6aWX8ve//52VK1f6uvwmea2nYIxZROPnCWYdZJ0ngCe8VVND1WLHoqGglDpCF198MYsXL2bIkCGICE8//TRxcXG8//77PPPMM9hsNsLCwvjggw/Iysri+uuvx+VyAfDPf/7Tx9U3TZrqAh0LUlJSzJFOspP5aD9ywwaQct+XLVyVUspbNm7cSP/+/X1dxjGlsb+ZiKwwxqQ0trzfDnNRY7FjdVb5ugyllGpT/DYUai3B2Jx6+EgppRry41CwY3PqmOxKKdWQ34ZCnTWYQJeGglJKNeS3oeAMCCbQ6DkFpZRqyI9DIYQgU+PrMpRSqk3x21AwthCCjR4+Ukqphvw7FKjBeG4mUUop5cehgC0EixhqqvWyVKVU8+3atYt+/fpx4403MmjQIK666irmzp3LyJEj6d27N0uXLuXHH38kOTmZ5ORkhg4dSllZGQDPPPMMw4YNY/DgwTz88MM+3pPGeX3o7LZKAkMBqKoowx5yfM+kpNRx6dsHIHdty24zLgnOffKQi23bto3PPvuMN998k2HDhjF16lQWLVrE9OnT+cc//oHT6eSVV15h5MiRlJeXY7fbmT17Nlu3bmXp0qUYY7jgggtYuHAho0aNatl9OEp+21OwBrlDobqyZcdjV0od/7p3705SUhIWi4WBAwcyduxYRISkpCR27drFyJEj+eMf/8hLL73Enj17CAgIYPbs2cyePZuhQ4dywgknsGnTJrZu3errXTmA3/YULJ5QcFTqlJxKHZOa8Y3eW4KCguofWyyW+ucWi4W6ujoeeOABxo8fz6xZszj55JOZO3cuxhgefPBBbrnlFl+V3Sz+21Owuw8Z1VRpKCilWtb27dtJSkri/vvvJyUlhU2bNjFu3DjeeecdysvdnzlZWVnk5+f7uNID+W1PISAoBIBaDQWlVAt74YUXmD9/PlarlQEDBnDuuecSFBTExo0bOeWUUwAICwvjww8/JCYmxsfV7stvQ8Hm6SnU1ZT5uBKl1LEkMTGxfq5lgPfee6/J1/Y3efJkJk+e7M3yjprfHj4KDHHP01xXrVNyKqXUXn4bCkHB7lBw1mgoKKXUXv4bCp57E4yGglJK1fPbUAgOdfcUXA69o1kppfby21CwB7t7CuLQnoJSSu3lt6FgsVqpNEFQqz0FpZTay29DAaBagpA6DQWllNrLz0PBjlV7CkopLwoLa3rAzV27djFo0KBWrObQ/DoUHGLH6tQpOZVSai+/vaMZwGHRUFDqWPXU0qfYVLypRbfZL6of9w+//6DL3H///SQkJHD77bcD8MgjjyAiLFy4kN27d1NbW8vjjz/OhRdeeFjvXV1dzW233cby5csJCAjgueee4/TTT2f9+vVcf/31OBwOXC4XX3zxBZ07d+byyy8nMzMTp9PJ3/72N37/+98f8X435NehUGsJxqahoJQ6DBMnTuSee+6pD4Vp06bx3Xffce+99xIREUFhYSEnn3wyF1xwASLS7O2+8sorAKxdu5ZNmzZx9tlns2XLFl5//XUmT57MVVddhcPhwOl0MmvWLDp37szMmTMBKCkpabH98+9QsAYT7tCxj5Q6Fh3qG723DB06lPz8fLKzsykoKKB9+/Z06tSJe++9l4ULF2KxWMjKyiIvL4+4uLhmb3fRokXcddddAPTr14+EhAS2bNnCKaecwhNPPEFmZiaXXHIJvXv3JikpiT/96U/cf//9TJgwgdNOO63F9s+vzyk4A4IJdFX7ugyl1DHmsssu4/PPP+fTTz9l4sSJfPTRRxQUFLBixQpSU1OJjY2luvrwPluMMY22X3nllUyfPp3g4GDGjRvHDz/8QJ8+fVixYgVJSUk8+OCDPPbYYy2xW4Cf9xSc1mCCjIaCUurwTJw4kZtuuonCwkJ+/PFHpk2bRkxMDDabjfnz55OWlnbY2xw1ahQfffQRZ5xxBlu2bCE9PZ2+ffuyY8cOevTowd13382OHTtYs2YN/fr1IyoqiquvvpqwsLB9Rmo9Wn4dCsYWgh0NBaXU4Rk4cCBlZWXEx8fTqVMnrrrqKs4//3xSUlJITk6mX79+h73N22+/nVtvvZWkpCQCAgJ47733CAoK4tNPP+XDDz/EZrMRFxfHQw89xLJly5gyZQoWiwWbzcZrr73WYvsmTXVZjgUpKSlm+fLlR7z+4jfvIiXrI2yPFrdgVUopb9m4cSP9+/f3dRnHlMb+ZiKywhiT0tjyXjunICJdRWS+iGwUkfUiMtnTHiUic0Rkq+d3+wbrPCgi20Rks4iM81Zt9Wwh2MSJo0Z7C0opBd49fFQH3GeMWSki4cAKEZkDXAfMM8Y8KSIPAA8A94vIAGAiMBDoDMwVkT7GGKe3CpTAUACqKsoIDLJ7622UUn5u7dq1XHPNNfu0BQUFsWTJEh9V1DSvhYIxJgfI8TwuE5GNQDxwITDGs9j7wALgfk/7J8aYGmCniGwDhgOLvVXj3lCoriwlMiraW2+jlPJzSUlJpKam+rqMZmmVS1JFJBEYCiwBYj2BsTc49s5aHQ9kNFgt09O2/7ZuFpHlIrK8oKDgqOqyBrlDoaZS71VQSilohVAQkTDgC+AeY0zpwRZtpO2As+DGmDeNMSnGmJTo6KP7dm+1uweqclSVH9V2lFLqeOHVUBARG+5A+MgY86WnOU9EOnle7wTke9ozga4NVu8CZHuzvgC7u6egoaCUUm7evPpIgLeBjcaY5xq8NB2Y5Hk8Cfi6QftEEQkSke5Ab2Cpt+oDsHl6CnUaCkopBXj36qORwDXAWhFJ9bT9BXgSmCYiNwDpwO8AjDHrRWQasAH3lUt3ePPKIwBbsHue5roaDQWllHeEhYVRXn7sfMZ48+qjRTR+ngBgbBPrPAE84a2a9hfkmafZWa3zNCulFPj5MBf2EHdPweXQUFDqWJP7j39Qs7Fl51MI6t+PuL/85aDLtOR8CgsWLODhhx8mNjaW1NRULrnkEpKSknjxxRepqqrif//7Hz179uSzzz7j0UcfxWq1EhkZycKFC3E6nTzwwAMsWLCAmpoa7rjjDm655Zaj/hv49SipQaHuUDAaCkqpZpo4cSKffvpp/fNp06Zx/fXX89VXX7Fy5Urmz5/Pfffd1+Sop/tbvXo1L774ImvXruW///0vW7ZsYenSpdx44428/PLLADz22GN8//33rF69munTpwPw9ttvExkZybJly1i2bBlvvfUWO3fuPOr98+ueQkhoBADGofM0K3WsOdQ3em9p6fkUhg0bRqdOnQDo2bMnZ599NuC+4W3+/PkAjBw5kuuuu47LL7+cSy65BIDZs2ezZs0aPv/8c8A90c7WrVvp3r37Ue2fX4eCNSCAGmNDtKeglDoMe+dTyM3NPWA+BZvNRmJiYrPnUwgKCqp/bLFY6p9bLBbq6uoAeP3111myZAkzZ84kOTmZ1NRUjDG8/PLLjBvXssPE+fXhI4AqCULqdEpOpVTzTZw4kU8++YTPP/+cyy67jJKSkqOeT+Fgtm/fzkknncRjjz1Gx44dycjIYNy4cbz22mvU1tYCsGXLFioqjv4Lrl/3FACqsWOp1cNHSqnm88Z8CgczZcoUtm7dijGGsWPHMmTIEAYPHsyuXbs44YQTMMYQHR3N//73v6N+L7+eTwEg7bGBFIX04IQ/fdNCVSmlvEXnUzh8bWY+hWOFQ+xY9fCRUkoBeviIWmswNpdOsqOU8h6dT+EYUmuxE1K729dlKKWayRiDe2i1Y4ev5lM4ktMDfn/4yBkQTKDRnoJSxwK73U5RUdERfdj5G2MMRUVF2O2HN6uk3/cUnNYQgvTwkVLHhC5dupCZmcnRTrDlL+x2O126dDmsdfw+FFy2EOxoKCh1LLDZbEd9x646OL8/fGQCggk2Nb4uQyml2gQNhcBQgqQWp+d2cqWU8md+HwoSGAJAZcXBpo9WSin/oKEQ6J6nuaaizMeVKKWU7/l9KFg8oVBdqaGglFJ+HwpWu6enUHXszKGqlFLe4vehEBDknqe5tkp7CkoppaEQ7AmFau0pKKWU34dCoCcU6qp19jWllNJQ8ISCU3sKSimloRAUEg6As0Z7Ckop5fehYA+JAMA4NBSUUsrvQyE41N1T0FBQSikNBQKD7NQaK9RW+roUpZTyOb8PBYAqCcKioaCUUhoKANXYEQ0FpZTSUACoETtWZ5Wvy1BKKZ/TUAAcFjvWOg0FpZTSUMAdCjbtKSillPdCQUTeEZF8EVnXoO0REckSkVTPz3kNXntQRLaJyGYRGeetuhpTaw3G5tJQUEopb/YU3gPOaaT9eWNMsudnFoCIDAAmAgM967wqIlYv1rYPpzWYQFd1a72dUkq1WV4LBWPMQqC4mYtfCHxijKkxxuwEtgHDvVXb/pzWYAKNhoJSSvninMKdIrLGc3ipvactHshosEymp+0AInKziCwXkeUFBQUtUpDTFoJdQ0EppVo9FF4DegLJQA7wL0+7NLKsaWwDxpg3jTEpxpiU6OjoFinKBIRgNzUtsi2llDqWtWooGGPyjDFOY4wLeIvfDhFlAl0bLNoFyG61wmwhhEgNLqez1d5SKaXaolYNBRHp1ODpxcDeK5OmAxNFJEhEugO9gaWtVZcJdM/TXK3zNCul/FyAtzYsIh8DY4COIpIJPAyMEZFk3IeGdgG3ABhj1ovINGADUAfcYYxpta/tlsAQAKoqyggJi2ytt1VKqTbHa6FgjLmikea3D7L8E8AT3qrnYCTI3VOoqdSeglLKv+kdzYB1byhUlfm4EqWU8q1mhYKIhIqIxfO4j4hcICI275bWegLs7lBwVGooKKX8W3N7CgsBu4jEA/OA63HfsXxcCAhyz75WW62Hj5RS/q25oSDGmErgEuBlY8zFwADvldW6bMFhANRV65ScSin/1uxQEJFTgKuAmZ42r52kbm1Be0OhRnsKSin/1txQuAd4EPjKc/loD2C+16pqZYEh7lBwaU9BKeXnmvVt3xjzI/AjgOeEc6Ex5m5vFtaa7CERALgcGgpKKf/W3KuPpopIhIiE4r7BbLOITPFuaa0nONR9otloKCil/FxzDx8NMMaUAhcBs4BuwDXeKqq1BdlDcBkBR6WvS1FKKZ9qbijYPPclXAR8bYyppYlRTI9FYrFQRRBSq6GglPJvzQ2FN3CPVRQKLBSRBKDUW0X5QpXYsdRpKCil/FtzTzS/BLzUoClNRE73Tkm+USNBWOp0nmallH9r7onmSBF5bu+MZyLyL9y9huOGQ4Kxak9BKeXnmnv46B2gDLjc81MKvOutonzBYbET4NSeglLKvzX3ruSexphLGzx/VERSvVCPz9Ra7dicOk+zUsq/NbenUCUip+59IiIjgePqa3WtNYRA13G1S0opddia21O4FfhARPZOS7YbmOSdknzDaQ0m0GhPQSnl35p79dFqYIiIRHiel4rIPcAaL9bWqlwBwdg1FJRSfu6wZl4zxpR67mwG+KMX6vEZly0Eu6nxdRlKKeVTRzMdp7RYFW2AsYUQTDXG5fJ1KUop5TNHEwrHzTAXAGILxSqGmho92ayU8l8HPacgImU0/uEvQLBXKvKVwBAAqivKsAcfV/flKaVUsx00FIwx4a1ViK9ZgtxBUF1ZBsT5thillPKRozl8dFzZGwo1lWU+rkQppXxHQ8EjIMg9JaejSudpVkr5Lw0FjwC7u6egoaCU8mcaCh4Bwe6eQl21hoJSyn/5ZSgU56Yx96X7Kc5Nq28Lqg8FnadZKeW//DIUcralEv/qdFZ/8159W2BwBADOGu0pKKX8l1+GQr9TxlMSZqHyx4X1bUEh7p6CcWhPQSnlv/wyFKzWAAqTuxG7LgdHjXu2teBQ9y0ZpkZDQSnlv/wyFADanT6W0GrD2vlfABAc4gmFWp2SUynlv7wWCiLyjojki8i6Bm1RIjJHRLZ6frdv8NqDIrJNRDaLyDhv1bXXkPHXUmeB3DkzALBYrVSZQEQPHyml/Jg3ewrvAefs1/YAMM8Y0xuY53mOiAwAJgIDPeu8KiJWL9ZGeLsYsnq3I3TZpvq2arEjdTognlLKf3ktFIwxC4Hi/ZovBN73PH4fuKhB+yfGmBpjzE5gGzDcW7XtJSNSiM13kL5pGQDVBGGp08NHSin/1drnFGKNMTkAnt8xnvZ4IKPBcpmetgOIyM0islxElhcUFBxVMX3GXwHApplTAaix2LFqT0Ep5cfayonmxibsaXS+BmPMm8aYFGNMSnR09FG9afdBIyjoaMO5aAkADkswAU4NBaWU/2rtUMgTkU4Ant/5nvZMoGuD5boA2a1RUGlKHzpv2U15SRG1Fjs2DQWllB9r7VCYDkzyPJ4EfN2gfaKIBIlId6A3sLQ1Coo7azyBTljz3YfUWYOxuapb422VUqpN8uYlqR8Di4G+IpIpIjcATwJnichW4CzPc4wx64FpwAbgO+AOY4zTW7U1NPiM31MVCMXzZlNnDSbIpT0FpZT/OujMa0fDGHNFEy+NbWL5J4AnvFVPUwKDQ8gZGEuHVbtw9h9IkNGeglLKf7WVE80+FTz6NNqVucgrqcZOja/LUUopn9FQAAZNuAaAiowi7NpTUEr5MQ0FIKZLH7K6htB+ZymB4qTWob0FpZR/0lDwcJycRJfsOgodViorynxdjlJK+YSGgkfCOZdgAdYWhVNTqaGglPJPGgoe/U4+jz1hQmVWEDWVpb4uRymlfEJDwcNqDSC7TxRx6VbKS/Yfx08ppfyDhkIDlsEDCXHAzmWzfV2KUkr5hIZCAwnDxuKwQuXixb4uRSmlfEJDoYGIjvFk9HLSIzWPsj35h15BKaWOMxoKDQSFhNGtZxnBDljy3jO+LkcppVqdhkIDQSERDAqvJCs2AMvXc3C5XL4uSSmlWpWGQgNBIeFYBApP6EKnnBrWzJ/m65KUUqpVaSg0EBIaDkCn3j2oDILMD972cUVKKdW6NBQasAUGsc3ak26FP5FzWl+6Lc+kMHu7r8tSSqlWo6Gwn+IB19LdlUbIiFOxOWH520/5uiSllGo1Ggr7STrnBkoJJTL7J9J7RRA26xfqah2HvZ3Ny2Yza+Jo8jM2e6FKpZTyDg2F/QSHhrMh9nwGl/2EjD+TDrudLJ/+1mFvZ/u//kH31HxWTL5er2JSSh0zNBQaEX/WndjESXBAFSVhFnZ//PFhrZ+1LZWE1XnkxQSSuGE38174k5cqVUqplqWh0IiuvZJYY0+hb9ZXFJ05lG7rikjftKzZ66e+4T4P0evt99g1IIqYd75l26r53ipXHYXMravI3r7G12Uo1WZoKDTBlXIjMRQTPGgACKx9+7lmrVdZvoeYuatJGxJLl95DOfHFd6gJFNLv+yM1VeVerlodrg133cSae2/2dRlKtRkaCk1IGvM7cogmNv1b0gbHED1vdbM+1H/94BnCqgxxk/4AQEzXvtTdfwudsquZ+7cbvF22Ogwul4uO2RW0z9L5M5TaS0OhCdaAAHb1uIKBjjVYzxpDeKVh8dTnD7qOy+WCz2eRGxdE8rir69tH/H4y20f3JHHGGlZ++4G3S1fNlLtrPcEOiKgw7CnM8nU5SrUJGgoH0fecW3GYACKqdlHQwYbl3c8oLc5tcvk18z6lU3Y1rkvPwWLZ90875un3Kepgo/rhp9ldkOHt0lUzZK1fUv84Y/1SH1aiVNuhoXAQUTHxrG53BkmF32P70+1EFdWy6PaJTV5imvXum1TYhZOv+/MBr4VFdiDqyccIL3fyyx+v08tU24Ddm9fVPy7astqHlSjVdmgoHELEabcRJlVYHCVkXXs63VPzmP3P2w9YLnvHWhJW5ZJ3xiBCw6Ma3dag0y4i8/IR9FiWzbKv3/R26eoQHDt2UBUIToGK7Vt9XY5SbYKGwiH0OWEMW629iN38X86c8hI7Toij64c/snzmu/sst+rNJxEDSTdPOej2xj74MpVBQsHMr71ZtmoGW0YeRXEhFEcFQHq2r8tRqk3QUDgEsVjYPWgSia4MNi35nlGvfkpBdCDOh54he8daAKoqS+k4ZxVpg6Pp1m/YQbcXGBRCblInOqam43TWtcYuqCZE5JZT0yWaik6RBOfs9nU5SrUJGgrNMHjcH9hDGK6FzxIa3oEuL7+Erdaw/tbrqKkq59cP/0VEhSH62uuatb3Q00cTWe5iw6JvvFu4alJJUQ7tylwEdO+Gs2scUQU1GtJKoaHQLPaQMDb3v5ukmpUs+egReg0ZTeWf/0CX9Erm3HclrmnfkBcTyInnXdes7Q0ePwmXQMb3X3q3cNWk9LW/ABDeuz/2xO4E1UGOp+enlD/TUGim4b+bwoqwMQzb/m82LP6WU6+ewo7xg+n5w1Y6Z1ZRe/FZB1yG2pSouASyuodj/3XdoRf2sV3rF7Phlxm+LqPFFW52X23UaeAwovokAZC9oflDmSh1vNJQaCaxWOh783vkWOKI/v42CnMzOPuf75PeO4LSUOGUPzxwWNtzjRhKp+zq+vMSbdWWP93N7nsPb9+OBZXbtlBnga59U4gf4D4PtGfbRh9XpZTv+SQURGSXiKwVkVQRWe5pixKROSKy1fO7vS9qO5iwiPbUXvoe4aac3HevxmIJ4IwvfqTXjJmERXY8rG31Gj8RgA3T2+4dzvkZm4nfWU5UiZOsbam+LqdFSVo2RR0DsQXaie7al6pAcOzc6euylPI5X/YUTjfGJBtjUjzPHwDmGWN6A/M8z9ucHoNOYk3yQwyqSWXZe3/GFminQ6fuh7+dIaMpjAqgdtFiL1TZMtZ8+Z/6fyDbf5rl01paWmjOHio7u793WCwWimOCCcjI83FVSvleWzp8dCHwvufx+8BFvivl4IZffDdL253H8Ix3WLPgiyPahsVioSSlN503FVFRVtzCFbaMuvk/UxgVQLUNSlceP8fbHVWVdCisxSTE17dVd44iPLfMh1Up1Tb4KhQMMFtEVojI3nGLY40xOQCe3zGNrSgiN4vIchFZXlBQ0ErlHijppjdJsybQdcFkcjO2HdE2Ys86j8A6WP3thy1c3dHbU5hF/JbdlI4YQH5iBMEb03xdUotJ37QUq4GQXn3q2ywJXYgqcVJZvsd3hSnVBvgqFEYaY04AzgXuEJFRzV3RGPOmMSbFGJMSHR3tvQoPITg0HOvE9wk0tdS8exFLv3iekt2Fh7WNIWdeSVUgFM/93ktVHmjL8rnNmnN61Vf/IcAFXSf8jrpBvYnNqqK8pKgVKvS+vI0rAYjpn1zfFtazLwDpG5Y0topSfsMnoWCMyfb8zge+AoYDeSLSCcDzO98XtR2Obn2S2Tbm31iMk+FrH8H+Qj9WPns+q2Z/iKOm+pDrBwaHkDMojg6rdnl9gLz8jM3MvGIMzqvvYvZjh55UpmreD+wJtzDwtIvoMGwEVgObfz4+Lk0t3bIBgISkkfVt0f2SAcjflOqDipRqO1o9FEQkVETC9z4GzgbWAdOBSZ7FJgHHxOBAQ07/HV3+tp4tF0wnNeZCEstTGfrLHVT+sydLXrmBirI9B10/ZPRptCtzsXGxdz5wXS4XP7z+N9LPv5gua/Io6GAjesbSg37rrygrpvO6fIqG98JqDaDvaecDkL90oVdqbG3OXensjrDuc8VY1/7DAajYttlXZSnVJviipxALLBKR1cBSYKYx5jvgSeAsEdkKnOV5fkwQi4U+J4zmpDveJvwv21g96i22hw8nJf8Lsl48i+L8pidwSTp/Ei4g7duWv7s5fdMyZl88kk4vfE5xp1DCPn6TyMf+j7Aqwy9vPNrkeqnfvEdQHcSeeyEA7aO7khcTCGs3tXiNvmDPLKS0U/g+bWGRHdgdYcWZ3rJzXTiddXz72E2s/mFai263oZqqcmbefxW71rfdK9nUsaPVQ8EYs8MYM8TzM9AY84SnvcgYM9YY09vzu21eknMItsAghpxxOSfe9xVrT32VbrU7qXxtLFk7Gr8xqmPnnmQnhhL0a8tNHu901jH7mckU/+5aYnbuIfOW8YydsZieg09jyNjLyegeRugXP+CoqWx0/d2zv6U8WBhy1sT6tvJ+XYjevvuYHx/I5XIRlV9FXbe4A14rjQvDnt1y/+xcLhffTr6MxKmLyH/yqRbb7v7m3H8tPb5eyfrHH/Taeyj/0ZYuST3uJJ91JbvGf0yYKSPog3PYtvrnRperOzmZzplV5KZtaPT11HmfsHpe879pfvfgtXR9ezY5faKI/fJjzrr3WazWgPrXI264jqgSJ7988PQB6zqqKum0Kou8od0IDAqpbw854QRCqw071/zU7Dqaw+Vy8e0lI5lxz2Utut2m5KVtINgBQd17HPBaXZcY2udVtdj5ne8e+gM9524mLyaQLumVbG/hvx3AL5++SM/ZGykJs5CYmnfc3WSoWp+Ggpf1G34WJRO/oY4A4r68lHU/HXiqpMf4ywFY/81/92kvLylixu0XEHTHo8jdD7Ni1vsHrLu/he/9kx7TV7F9VA/GffYT8b2SD1hm+CW3kRsXBB9+dcA3/9TZHxJSY4gad+4+7YkjxwGQ9vPsQ9ZwOFLnTCVxQzHx89a3ytVNmet+BSCq3+ADXgvs3p2QGkNh9pFdYtzQ7H/dS/fPl7B9ZCL9/vsxLoFNU18/6u02lL19DbYn3yA73k7Mu28AkPqG93okyj9oKLSChH4nYLlpLgXWGPrMvZ7lM9/a5/XeJ55JcaSVmoWL6ttS533CqnPH0P2HrWw/uz/FHQORB55k46/fNvk+G3/9lohnPyCjexhnv/hZkwP0WSwW5KqLiM1zsPTL1/Z5Lf/bb6i2QfL4Sfu0Jw4cQVmIULUq9TD3/uDy3nqdWivYa2H556+26LYbs3vLegC6DBx+wGuRvfoDkHmU8zUvePvvdH3rO3YOjmbca18RlzCA9P7taTd/dYsdfqt1VLPurhuxOg09XnyFHkmnkjYklpi5q/VeC3VUNBRaSUx8d6Lu+oFtQQNIWfYnFr9xB9VVFYD7Q3p3Sk86byxkT2EWM//0e2x3PIoYQ/ULf2HCS1/S590PqQq2UnLnn0jfdODdxYXZ2ym+ZwqVIVaS3/qIwOCQA5ZpaMS1f6Y40krZO7+NvVRX66Dj8h1kJ8UREtZun+UtFguFvToQvqXpk+aHa9uq+SSuKyLz4pMojrRSNfO7Ftt2Uxzbt1MZBNFd+x7wWqf+JwKwe+v6I97+r1+8Qod/TSW9VwSnvzcDW6AdgJAJ5xFV4mT17KlHvO2G5jx6M113lFFy10S6DxoBQNykPxBWZVj8/oGHBZVqLg2FVhTZviM97v2epVHnc0rOh+Q+cxJbV7kv84w+81yCamHTOWfTY8Yado7uyZBvf+DEc64BoHOPJGJf/zcBdYZdN9xAYfb2+u06aipZcdMVhJU7iXzuCWK69Gn0/RsKDAqh4rKxdN1ZTuq8TwBYt/BLIstdhJ05ttF1LEn9iSmopSinZQaO2/Tvp6kJgJPueJg9owfTdWMx+ZlbWmTbTQnIyKc4NqTRXlTnnkNwWKF6x/ZG1jy01DkfY3/43+R3snPKB18THBJR/1rK726nKhCyP//4iGvfa8Ws90n4YhnbR3Tj9Jserm9PHnc1uXFByOffev2+F3X80lBoZfbgUIbf/SFrRr9NiKuC7v+7kMX/uZf+Yy6hwi4YgZJ/3MWEN2YQ3m7fkT56DR2D7V+PEFFSS+q1v6O8xH0H9ez7rqTb9jKKJ09k4KkXNruWETc/RHmwkP36KwBkzvicWisMvejGRpePPWk0AJt/OvoZ43LTNpCweBeZo/vQoVN3+l5xE1YDqR+/ctTbPpjI3DJqujQ+om2ALZDi6CAkI+ewt5ufsZm6KX+ntJ2NwR98RkTUvlc3hYZHkT08kc7Ldh3VWFeF2dtxPPw0RR1tjHn+o31es1gsuC47l0451aTOaZkeifI/Ggo+Mvj0ywiavIxV7c7ilMx3KPj32Tif+gsDv5/HyZfc3uR6Q8ZeTuVDtxGXVcWiSRcw94Up9Jy7mR3nDtrnW2NzhEV2oGD8cLqvLWTrinm0+3UTWf2iDvhA26vviPHUWWD3sqO/Hn7Fvx/DYiDpzr8C0Gvo6WTH27HMXnSINY/cb1NwJjS5TFVcO8JySg5728tefpTgakPnV14mOr5Xo8t0uuxKgh2wbNqRBZ/TWceyu64ltNJF9LNPNTpc+8mTplBhF3Le+88RvUdr2J2fztYV83xdhmqChoIPRbbvyLB7p5E68jUinbs54Ze72fjR/WxdtRBzkO7/iMvvJv/uS0nYtJv412eQ1rcdZz/13yaXP5iT73yUGhukPfBnOux2EnjG6CaXDQlrR26XEAI2HNnhlb3K9uQTN3sNu4bGkdD/txO+dWeOID7DO5duAqR7rjwK792/yWVMt860L65t8h6OxpTtySfu+1R2nRBHryFN//2Sz7qC4nZWqmY0fbHAwfz80TMkri8m9/px9D/53EaXCQ2PIu/MJBLa6OWpdbUOVlx1MZWT7iRnZ9ufedAfaSi0AclnXUnAnUtYFXUOQwpn0vvr89n1+FB+nfp3dhc0fijjjNseJ/26saT3DOektz6tP6F5uKLiEsg8vT/xGZW4BIZcfMNBl68Z0J24tLLD+tDc3y+vPUpIjSHhtsn7tCdfeaf70s2P3zjibR9M4aZVAMQNSGlymZCevQhwQeaWlc3e7i+vPdLo/uzPag1gz+nJdNu0u8l7Ug6m5qMvKOgQwNh7nz3ockNueQChbV6euuC1vxGfUUlgHax4Sm+2a4sCDr2Iag3tOsYxfPJUSnYXsnrOu7TfMo2TtzyLY/PzrAwfSW3CGKwhEdiCw7EFRxIYEsHAy24l4MrJlBYXUpC5E0dVKXVV5dRVlSLWAAafeTW2wKBDvvfQux+ieO4VZHcPZ2DnngddNvLE4QR+t57Nv35P0uiLD3s/HTWVhH/1I+k9wxl32kX7vBab0J9VfdsTuSAVl8vV7Dmvm6ty21bqLNCz74lNLtOh72DgM3I3rqRH0qmH3KajyrM/vSMO2J/G9L/yVmq+uonUD1/mnL++dsjl91q74Au6pFWQceO4fW5EbEyX3kNZMySm/vLU/a8k85WinJ1EvvsN6T3DqU2II3H+Vnau+6X+6inVNmgotDGR7Tty0uVTgCnsXL+EvIXv0DdvFu3XH/5gdJtXvkH4VR/QuXu/gy4X3yuZnX+9gW49mj6sslfvURPY/cS7ZP/6wxGFwi8fPE1sqRPL/ZMafd0+/mw6/OtT1syfRvLYiY0uc6Qk3T0FZ8M7tffXdcBwcoHSrc2br/nnD54krtSF9cHrm7V8j6RTmZMQStCcxbgebH7wpb3zGp2C4JQb/9Ks5eMm3UDwvf/k1w+e4Yzbn2jWOt62+KE7SKgx9Hjsn0TGdCH7p4vY8NTf6P5fPb/QlmgotGHdB55E94EnUeuoIS8/k+ryEmoqS3FUlOCoLMVZVYpxOrDYwwiwh2MLjiAwJJygkHDytyylz/KHkffGsGL445w4vvEriozLxep5n9Au/RvKilIp6ZNCZIfYJmuKSxjA9nZW6lYf/vFgl8uF+eh/5MUGMuri2xpdJuXyO9n20qdkfv5Ri4dCaPZuKuKjDrpM+5hubA0R6tLSD7k9p7MOmfo1uXFBjL7w0MOR1ztnDHFvzGTz0u+bPDfQUPaOtSQszyLt7IGc2K7RuacOkDzuan6Mew4+m4Xr1r+3eK/rcK3+YRo9f9rJjvOSGH+i+5LnZecOpcf0VWz89dtm/R1U69BQOAbYAoOI7XLwwzr769YnmexBoyn78FpOXHYfS7fNJ+nG1wkOdY8O6nI6SZ39AZHLXyTZuZM8OtCheg17Xv6JVac8xtBxjX+TB9jdJ44OG3MO+xDP8ulvEZdbQ849lzW5XlhkRzKHxhO3eDuOqspD3oTXXI6aSqKKaikfEX/IZffEhmLLOvSsfsu+eoPYPAe59008rL9DylV3k/nWTNI+ebtZH4arXv8niQYG33p/s99j7+Wpnf/9P1LnTOWEcVc3e92WVuuopujxf2KPsDD64d/uWh8x5Sm2zx5HwTOP0/+LYy8UMrasoH1sImGRHXxdSovSE83Hsc6Jfenx54Us7jyJlOKZ5P/rFLav+YXlM94k/YlkTlhyD4GuGpYl/4MOf93ErktmUGKNYujiu1n57PkU5jY+jHTgkCTalbn48ZNn2Zr6E8X5WQe9Wgrcx953/+cd9oRbOHXSwU8wdrzoEkKrDcu+brkTzukblhLggtBevQ+5rCO+I5F5FYdcruTd9ymOtDLy2imHVUv7mG5kDI4l+qcN1DoOPhlTRVkxMXNSSRsSQ7d+ww7rfU6eNIXyYKHuwX/w7SM3UlJ0+PdftIT5Lz1Ap+xq6u68dp/LaNtHd6Xw0lNJXF9M6pyjv6mvNRXl7KTgsqv5+cpzj7sbBTUUjnO2wCBOufkl1o99n1BXGT2/PJeU5VMAw/KUZ+j817UMu+gOAmyB9Boykm73/8qviXcwqOwXAl4/mWVfv0pdrYOtqxby60ePserp82if/RUAloX/pvf/JhD16gCqH40l/bEBrP3n6Sx98Sp+nfp31i2aTkFOGj++8zhLxp5Et22llF1+5kG//dfVOkg88SxKQ4SCzz5h09I5hwycvSrK9vDjJ0+z8rsP2LpqIYXZaTjr3GMN7Z2CM7r/0ENuJyCxG5HlroN+iK5Z8DndtpdRfsnpBz1H0ZTIiy4kosKw4pu3D7rcr+89TViVIe76mw77PULDowh79RmKurcn8ZOf2XbGWGb95RqKc1tvvu38jM10+O/3pPVtx6lXHxiep93zJHvCLeQ/99wx9eH663MPEuyAbtvL+Pmjg18NdqwRY4yvazhiKSkpZvny5b4u45hRlJfJ1s8fIbDHSJLPvhaL1drksmmbVlL1+e30q9tIjbERJLUAZEocGeHJ2N9dw47h8fT4/XXUFKXBngwCK7IJq86hY10u7Uwpy4rDqUgNo1OBkB0t7B7Zjc7de2Ktq0bqqrDWVWFxVmNzVhJcV0qks5j2pgSrGGasj6HrhgASLs4l396L8mF3k3zmlY3WXFKUx8/vPYBr3mJ67hCy4gwRg8tJaV+GCwtF0p6fdoYycEkdnRbNo13Hzgf9O/388XNEPfoWeY/ezKDRlxLRPobAoH0v+Z01cTQxmwro9+PCRm8iOxRHVSWrR6RQ2L0dZ326gABb4AHLuFwuFo4ZiivAwpi5K47qvMCGX2aw66Vn6Z6aR7UNss9KYti9fyemkTGgWtKM686m27IMwj55q8mrueY8/ye6vDGTkifu5ORL7/BqPbWOanbnpzdrKJimFGRtI+uc88ka3ImQrGJsNXWcMGfREV3l5XK5KM7dibPWQWzCoS/0aCkissIY0+i12RoKqknOujqWf/k8FGwiIPEUug09k+jOiQB8d8HJBJZV0+8/HxywXu62NeS/+CIJO8opbCfkDI9iSMdyEp2ZCC6qxU41QdSIHYfFTq3FTnVABI7gaFwhMUhEHIWFhfR46RvWnN+bU8M2EW/ySLN0JX/wrSSfdxO2wCAKczNYM+0Ryn9ZSPc1AdRZYfuweOLW59ChxMWuLjYqR/SgW5SdzAVric1yEX1hKHL+i/QaMvKAusHdU5nz5gMkvvwtuaMrOL2T++7mCmOnVMKpsEaw0xFO58/y2T5hMBc8++kR/32/e+I2Ev67gB0nduKs/8w4oAe1dPpbhP/5OXLv/R2n3/JYk9sxLhe1tQ5czjpcLicul8t9Ut/lwricRLSPrg/TrSvmsfmlJ+m+NJM6C2SM6cPQex9tdIj1o7Xy+w8JnvwEOy46gfFPftTkco6qSpaMPYnaoABGz112yEtuj1R5SSE/XzWeLttL2Tm8C/3u+Su9ho457O3M/OPlJH67Fvunb7I7Yxuh9z3NrokjOPeRg/f60jYsYd1bz0J+EbbiMkL2VBFR6sTmBBdQ+OerGP2H/zuifTtcGgqqxc366yS6f9H0ENOloULpVecw+rbH6z/sjMuFNPPbrsvlYtGoZMRlKB2TTJUdOlemclJQOgUSTVp4Mns2rqDdSjthlbBlWBwjHn+V2IT+OKoq+fH1hwj9+Fval7pI7x1BSFElJZEBnHySuzeyLG4iSVc/SWh4u/raUudOJerXJ+lUm8GWzzuz/tROJJ51Dq6KIqRqN9aa3QQ69rBzSSbdN0PHC4rJ63ASliETGTDqkgN6E9WV5eSlbWZPzlZsIe2I7z30gCu79gbDrv7tOe29b/Y5afntZacStbOYwT8uJm3jMvas+JKOBb8S5Koi0NQQiIMg4yAIB1Zp+v/jNEsXioZPYejZ19b//XetX8y6F/5Ows/uwQ3TRnZn0D1/I3HgKc3673Mo+Rmb2fz7y7C4DMlzFhIafvCrvha8/Rixz3xMwf3XMOr65l12ezhKinJYctX5dE6rYNdJXYhfkUlgLew6IY6ek++n30nnNGs7+RmbyT73IjJTujLhPffcIrMmjqbT+nw6zfiCuIQBja6Xm7aB7ZdfTni5kz3tbFS1D6a2QwQSHYUtNg6Zs4iovEpiP59Kl96HPsR5tDQUVIvbU5jFys9fxzidB7xmtdtJuez2Izqs0tAvn75I3ctv06GoFovnn2mNDfI7CLZaF3FFQlpiCF3/9jADR15wwPpVlaX89MrfiPh0LpHlLraf1Y/THnuLTR/+kZOKviaXjuSe+jiBoe2wzHuUfnUbSbfEU3TS/ZQ99ixlCR0ZP3U+4L78NH3jUjKW/0i7Zz5g27DOxA9LpHfBbKIoZQ9hbGk3CjEuwioz6FCbQwwHDnxXSDtygxIpj+yDJaY/IbE92fbjN/T+6GeyEkIZ9t+vaB/dla0r51N35e2sPjmCsYl5RLMbh7GyxZ5ETWAUTqsdE2DHWIMwtmAICAKLDREBscDe385aOu38ggRXJlsDelM96q8MOvXC+nDI2pbKqhceoeuCzQQ4YeewePpOfpDeJzY+Um5z7M5PJ/XyC2hXVIPlxUcZcsblFOdnkbVpKRXpqQTkr0OMCxl0CQNHX0qQPQSns46FY1Ow1joZOnPeAYNBHo3dBRmsuPIiYrMqKfnLHzj16ikU5ezk1xf+j07friTYAVt62ojtW46ccgfDL723yS8vMyZfSuLsDYR+9nb9TXdpG5dSctkk0od3Y8K73x+wTmlxLssvPYd2RTXYX3+GASMmHLBM+qZlFF5+LYVdwjnj60WNHk5sSRoK6phWUVbMrtU/kbd2GZWbNhKwIwtblQPbtb/j1KvvP+Sx9oqyYpZOfYG+Z15G557uGdc2LZ2D/bs/kuhy34+QTxS7Bt3FCRfeSYAtkG8vO5XI9D0UD00kaFcuHbMrsLtPq1AeLMR89C4JA9z3kGz4eTq1qz6hX8nPVEowhYHxVIR0oS4yAVt0T8Jie1BTvpuqzLVYCzfTrmI78bXphEhNfY2L8iOI+DGMwvaGuFG1bN0aQPcNFiIv2ENRVAqufhPoc9plRLQ7/Msf62odrJzxOt1Wv0QcBawPHELA2Y/QN+UMwN1LSt+WyqqXHyVhwRYCa2HzkPaEn3s2kZFRuKrLMY4KcFRgqSnF6ijBVltGUF0ZdmcZIa4K6iSAGglht8tO4YIy4goM2yZ0pmd7oVP19n0CMo8OBFBHB0ooJZRN7U8nNOVKyguzCH3gefI62xn4zkdNfus+GEdNNVnbVlO0czUWWzBRCQPZfscNROdWU/7QrYz4/W9DkewuyGHVhw9SuWIRcetshFZD1sgqonv3Iv7at+nYed+BE3PTNpA3/lIyhifQ/95HKJ77HBZnDY6oPmQsXknST9lU//shhp55xW/1VFXyw+/PIH5bCVX/uIfhF93SZO3z33yYuOemsWviSM59xLsDGmooKNUIR001q756HuNyMuTCyfX3cMBvh8cq7EJRl3Bqe8QT0q8/sUNOovuQUUc9dITL6SQ3fSu7c3bgKCugtqyI9HWL6fnFOspChfAKw46B7Tnv7e/3qeto1FRXsurL5+iz5Q2iKCVDOmM3VUSY8voLCYprrSze0Z74tYFYXZA2sI7hvYqJCarDZYQyCaFCwqi0hFEdEI4jIII6Wxhi6nBWlbB7XiZdsw0ZYy2c2LGSCksEheF9cMYMIqxbMvH9htM+uhN1tQ42/PwNNas+YcCehYRKNXl04KeqHvSclUWlXdgzoTsxkeGIqxYxTpzWYFyBYRAYDvZwJCgca1AYtbszsBVtokP5VuKdmQSKu/da4Ahg3cJoonYLWy7uQ9L5d9Bz6GiqKstZ/8U/GJz+IXZqWNluHJFn3MW2vz9A93VF7Brh4JRu1Wwf/hgnnvfbWGAz7rqYxLmbyL08jjNlJWUmmBJLJJ1deVQ4hfXfxlEWbug9RqgM7ACuWjYvK6ffZhebxwQwuLOFOksgJaGJ1HXoR3D8QGJ6JBPXrTcWq9U9X/k1Z9JtVQ6WN588YBj8WkcN2dvXUbgzldrs9Vg79mDYRXce0b8FDQWlDlNdrYPivF107NyrVe8GXrvgC2ru+Ruh1QbefZb+p4xv8feoKNvD2i+eJrBgDXWBkTjt7SA4CmtoFLawKGyh7akoLyF72gf0XpxJbQBknpvMaVOepV104zf/OaoqmXfVWXTbUHzYJ0yrKspYv+ATAtZ9Tq/K1WwpD6RmQSiBtVAyxkmfDoLBQqCpIcRUEko1lv3OoeQSTV5wDyrb98XWOQljj6D8kSdov6eO7LPsjIvYiVUMZSYYIxYiqGBl2Cg6THiUhH4nAFBTVc68SefRfU0BG0cEcEm3dJaHj6X3da+x/teZhP75GTL61nHa4Ao2JFzDgIumENm+I9WV5WRtX8eKqf8i6at1rBsbyYD4ADasK2XQylrWnhxEn/6xGLEQ4KwitiZtn55TpQkiO6AL1QHhlDptmK+zqA0Q5IqTCLSHYyvLpEPFduKdGfWB5zTCivbnMvyeI7u/Q0NBqWPIjrWLyFzxE6Ou8/0oojvX/cKGp/5Gj2XZVNiF/H4xWAb2ISblVPqMOI+wyI7UOqqZfd259FiZS/YdFzL2rieP+n2ztqWy5cbr6JhfQ+Hkfa++cjmdVFWWUVm2h6ryPVhtgeRtWk7+ysU4N20hfEc+0UV1VNvA9cxfOPGcaygpLmD70pnUbv0Bq6Ocdmf+kV5DDrxE1lFVydzrz6N7ah6pp8dxWcxqaghkwfpwEjYEkHnLKE697p+ERx544tzprGPBuOGElNRQcuGpJHy4kO1jenHeq18f8MWipLiAnK2rKM1Yhyt/I8FluwisqyDQVcXOomo6fQfbBzgZn5RPvnQkP7gHle36Yus0gPaJQ4jvPQR7cOgR/301FJRSR2Xj4plsf+NFIrfk0LHYfUOgSyA/NojaYBtdd5aTPukMxj3YcjPnlRTlsPgPl5CweQ87LjqBqBNPpjwzDUdONia/AFtBCaHFVXTYXVe/TnE7KyWJHZEBvel9/lVHdMmpo6aSOX+YQI8VOWyYMIj24XvoOC2TXSMSueCtg8+FkTrvE4LueBSAnUkdOeujOUc0rP3MP/2eHjPWUPzwTYy84o+Hvf6haCgopVpMUc5Otv4yi+KVS5AN24jMKqVkwimc+9BbLf5ejqpKZt9xMT1/+W2AwjoLlEZYqWgfjCM6EmuPBKKGDKPnSWfR8RBDvzdXraOa72+cQM+lWRR0tNG+uJao6R83636OGXddjDUzj1EfzDjkpbhNcVRV8tOEkUQU11B199WEde5GZKcEOsb3Irx97FEf0tRQUEods1wuF6vnfow1MIiY7gPo2LmX1y/ZBPd5pe9umkDPXzPYfkZvJrw63evv2dC2VQsoue52Qmr2/Yx2WKE83MruU/ox4fnPj2jbBwsFHSVVKdWmWSwWhp59Vau/b4AtkHPemsEvHz/P6AuaN19GS+o1dAxlPy4ge2sqpbnplOdm4SjMo66wCFO0G1tcJ6+8r/YUlFLKzxysp6CjpCqllKqnoaCUUqqehoJSSql6GgpKKaXqtblQEJFzRGSziGwTkQd8XY9SSvmTNhUKImIFXgHOBQYAV4jI4Q+VqJRS6oi0qVAAhgPbjDE7jDEO4BPgwkOso5RSqoW0tVCIBzIaPM/0tNUTkZtFZLmILC8oKGjV4pRS6njX1u5olkba9rm7zhjzJvAmgIgUiEjaUbxfR6DwKNY/Vul++xfdb//SnP1OaOqFthYKmUDXBs+7ANlNLWyMiT6aNxOR5U3d1Xc80/32L7rf/uVo97utHT5aBvQWke4iEghMBFp3FCqllPJjbaqnYIypE5E7ge8BK/COMWa9j8tSSim/0aZCAcAYMwuY1Upv92YrvU9bo/vtX3S//ctR7fcxPUqqUkqpltXWzikopZTyIQ0FpZRS9fwyFPxlfCUReUdE8kVkXYO2KBGZIyJbPb/b+7JGbxCRriIyX0Q2ish6EZnsaT+u911E7CKyVERWe/b7UU/7cb3fe4mIVURWicgMz3N/2e9dIrJWRFJFZLmn7Yj33e9Cwc/GV3oPOGe/tgeAecaY3sA8z/PjTR1wnzGmP3AycIfnv/Hxvu81wBnGmCFAMnCOiJzM8b/fe00GNjZ47i/7DXC6MSa5wf0JR7zvfhcK+NH4SsaYhUDxfs0XAu97Hr8PXNSaNbUGY0yOMWal53EZ7g+KeI7zfTdu5Z6nNs+P4TjfbwAR6QKMB/7ToPm43++DOOJ998dQOOT4Sse5WGNMDrg/PIEYH9fjVSKSCAwFluAH++45hJIK5ANzjDF+sd/AC8CfAVeDNn/Yb3AH/2wRWSEiN3vajnjf29x9Cq3gkOMrqeODiIQBXwD3GGNKRRr7T398McY4gWQRaQd8JSKDfFyS14nIBCDfGLNCRMb4uBxfGGmMyRaRGGCOiGw6mo35Y0/hsMZXOg7liUgnAM/vfB/X4xUiYsMdCB8ZY770NPvFvgMYY/YAC3CfUzre93skcIGI7MJ9OPgMEfmQ43+/ATDGZHt+5wNf4T5EfsT77o+h4O/jK00HJnkeTwK+9mEtXiHuLsHbwEZjzHMNXjqu911Eoj09BEQkGDgT2MRxvt/GmAeNMV2MMYm4/3/+wRhzNcf5fgOISKiIhO99DJwNrOMo9t0v72gWkfNwH4PcO77SE76tyDtE5GNgDO6hdPOAh4H/AdOAbkA68DtjzP4no49pInIq8BOwlt+OMf8F93mF43bfRWQw7pOKVtxf+KYZYx4TkQ4cx/vdkOfw0Z+MMRP8Yb9FpAfu3gG4TwdMNcY8cTT77pehoJRSqnH+ePhIKaVUEzQUlFJK1dNQUEopVU9DQSmlVD0NBaWUUvU0FJRqhIg4PaNO7v1pscHURCSx4ci1SrUl/jjMhVLNUWWMSfZ1EUq1Nu0pKHUYPGPXP+WZt2CpiPTytCeIyDwRWeP53c3THisiX3nmOFgtIiM8m7KKyFueeQ9me+5ARkTuFpENnu184qPdVH5MQ0GpxgXvd/jo9w1eKzXGDAf+jfvOeDyPPzDGDAY+Al7ytL8E/OiZ4+AEYL2nvTfwijFmILAHuNTT/gAw1LOdW72za0o1Te9oVqoRIlJujAlrpH0X7olsdngG3cs1xnQQkUKgkzGm1tOeY4zpKCIFQBdjTE2DbSTiHta6t+f5/YDNGPO4iHwHlOMejuR/DeZHUKpVaE9BqcNnmnjc1DKNqWnw2Mlv5/fG454Z8ERghYjoeT/VqjQUlDp8v2/we7Hn8S+4R+gEuApY5Hk8D7gN6ifAiWhqoyJiAboaY+bjnjCmHXBAb0Upb9JvIUo1Ltgzg9le3xlj9l6WGiQiS3B/qbrC03Y38I6ITAEKgOs97ZOBN0XkBtw9gtuAnCbe0wp8KCKRuCeDet4zL4JSrUbPKSh1GDznFFKMMYW+rkUpb9DDR0oppeppT0EppVQ97SkopZSqp6GglFKqnoaCUkqpehoKSiml6mkoKKWUqvf/3epfGQKCnVEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curves\n",
    "pd.DataFrame(history.history).plot(figsize=(6, 4), xlabel=\"Epochs\", ylabel=\"Loss\", title='Loss Curves')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2eb856ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([20.171362], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# View the first prediction\n",
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bddfd2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70692576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step - loss: 16.4087 - mse: 16.4087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[16.40869903564453, 16.40869903564453]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83f8eb81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[20.171362 ],\n",
       "       [27.64308  ],\n",
       "       [19.848997 ],\n",
       "       [26.087652 ],\n",
       "       [20.063293 ],\n",
       "       [20.000437 ],\n",
       "       [34.76703  ],\n",
       "       [24.944166 ],\n",
       "       [21.835697 ],\n",
       "       [28.10452  ],\n",
       "       [45.14205  ],\n",
       "       [24.925735 ],\n",
       "       [26.595594 ],\n",
       "       [14.437489 ],\n",
       "       [31.463968 ],\n",
       "       [22.64205  ],\n",
       "       [38.799446 ],\n",
       "       [19.486162 ],\n",
       "       [23.506634 ],\n",
       "       [13.822616 ],\n",
       "       [25.220123 ],\n",
       "       [16.50094  ],\n",
       "       [16.165382 ],\n",
       "       [19.845291 ],\n",
       "       [ 9.276058 ],\n",
       "       [28.585705 ],\n",
       "       [22.052095 ],\n",
       "       [15.375547 ],\n",
       "       [15.851569 ],\n",
       "       [34.143898 ],\n",
       "       [13.636504 ],\n",
       "       [18.301992 ],\n",
       "       [25.771875 ],\n",
       "       [22.372623 ],\n",
       "       [21.071863 ],\n",
       "       [27.717339 ],\n",
       "       [20.702972 ],\n",
       "       [38.6063   ],\n",
       "       [22.230827 ],\n",
       "       [21.87205  ],\n",
       "       [21.07414  ],\n",
       "       [30.806051 ],\n",
       "       [10.334932 ],\n",
       "       [33.68103  ],\n",
       "       [43.94771  ],\n",
       "       [21.367332 ],\n",
       "       [20.624212 ],\n",
       "       [15.00712  ],\n",
       "       [37.391556 ],\n",
       "       [19.411673 ],\n",
       "       [21.595613 ],\n",
       "       [26.266726 ],\n",
       "       [18.836897 ],\n",
       "       [18.511953 ],\n",
       "       [21.423538 ],\n",
       "       [20.036547 ],\n",
       "       [24.202    ],\n",
       "       [ 9.061435 ],\n",
       "       [36.572174 ],\n",
       "       [23.388823 ],\n",
       "       [24.311796 ],\n",
       "       [33.36856  ],\n",
       "       [24.155684 ],\n",
       "       [23.240072 ],\n",
       "       [14.579473 ],\n",
       "       [29.742268 ],\n",
       "       [22.498234 ],\n",
       "       [27.333815 ],\n",
       "       [20.26318  ],\n",
       "       [24.194035 ],\n",
       "       [18.735899 ],\n",
       "       [32.36289  ],\n",
       "       [32.573025 ],\n",
       "       [15.984973 ],\n",
       "       [31.600544 ],\n",
       "       [11.477947 ],\n",
       "       [23.729116 ],\n",
       "       [11.46301  ],\n",
       "       [27.373743 ],\n",
       "       [51.996628 ],\n",
       "       [28.963022 ],\n",
       "       [15.818855 ],\n",
       "       [20.925142 ],\n",
       "       [18.44298  ],\n",
       "       [20.414389 ],\n",
       "       [33.705265 ],\n",
       "       [25.054302 ],\n",
       "       [25.317987 ],\n",
       "       [16.64032  ],\n",
       "       [21.761045 ],\n",
       "       [13.378287 ],\n",
       "       [14.6642065],\n",
       "       [21.50334  ],\n",
       "       [23.501127 ],\n",
       "       [16.506449 ],\n",
       "       [33.754707 ],\n",
       "       [22.151445 ],\n",
       "       [18.634119 ],\n",
       "       [21.412077 ],\n",
       "       [27.866327 ],\n",
       "       [ 9.936631 ],\n",
       "       [16.228058 ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9bb6e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 16.4087 - mse: 16.4087\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[16.40869903564453, 16.40869903564453]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8003eaaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sequential/Dense_1/MatMul' defined at (most recent call last):\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\lenovo\\AppData\\Local\\Temp/ipykernel_3364/1234241573.py\", line 1, in <module>\n      X_pred=model.predict(y_test)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2382, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2169, in predict_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2155, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2143, in run_step\n      outputs = model.predict_step(data)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2111, in predict_step\n      return self(x, training=False)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\layers\\core\\dense.py\", line 241, in call\n      outputs = tf.matmul(a=inputs, b=self.kernel)\nNode: 'sequential/Dense_1/MatMul'\nIn[0] ndims must be >= 2: 1\n\t [[{{node sequential/Dense_1/MatMul}}]] [Op:__inference_predict_function_5604]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3364/1899172436.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sequential/Dense_1/MatMul' defined at (most recent call last):\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\lenovo\\AppData\\Local\\Temp/ipykernel_3364/1234241573.py\", line 1, in <module>\n      X_pred=model.predict(y_test)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2382, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2169, in predict_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2155, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2143, in run_step\n      outputs = model.predict_step(data)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 2111, in predict_step\n      return self(x, training=False)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\", line 412, in call\n      return super().call(inputs, training=training, mask=mask)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\engine\\functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\lenovo\\anaconda3\\lib\\site-packages\\keras\\layers\\core\\dense.py\", line 241, in call\n      outputs = tf.matmul(a=inputs, b=self.kernel)\nNode: 'sequential/Dense_1/MatMul'\nIn[0] ndims must be >= 2: 1\n\t [[{{node sequential/Dense_1/MatMul}}]] [Op:__inference_predict_function_5604]"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ad15ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
